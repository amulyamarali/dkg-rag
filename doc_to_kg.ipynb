{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document to Knowledge Graph Conversion using REBEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMBINED RELATION EXTRACTION\n",
    "\n",
    "import spacy\n",
    "import torch\n",
    "import math\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Initialize model and tokenizer (example model, replace with actual one you're using)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Babelscape/rebel-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Babelscape/rebel-large\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Load spaCy model for dependency parsing\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "class KB:\n",
    "    def __init__(self):\n",
    "        self.relations = []\n",
    "\n",
    "    def add_relation(self, relation):\n",
    "        if relation not in self.relations:\n",
    "            self.relations.append(relation)\n",
    "\n",
    "    def print(self):\n",
    "        print(\"Relations:\")\n",
    "        for r in self.relations:\n",
    "            print(f\"  {r}\")\n",
    "\n",
    "# Extract relations using spaCy dependency parsing\n",
    "\n",
    "\n",
    "def extract_spacy_relations(text):\n",
    "    doc = nlp(text)\n",
    "    relations = []\n",
    "\n",
    "    for token in doc:\n",
    "        # Extract subject-verb-object relations\n",
    "        if token.dep_ == \"ROOT\":  # The main verb in the sentence\n",
    "            subject = [w for w in token.lefts if w.dep_ in (\n",
    "                \"nsubj\", \"nsubjpass\")]\n",
    "            obj = [w for w in token.rights if w.dep_ in (\n",
    "                \"dobj\", \"attr\", \"prep\", \"pobj\")]\n",
    "            if subject and obj:\n",
    "                relations.append({\n",
    "                    'head': subject[0].text,\n",
    "                    'type': token.text,  # The verb as the relation type\n",
    "                    'tail': obj[0].text,\n",
    "                    'meta': {'sentence': text}\n",
    "                })\n",
    "    return relations\n",
    "\n",
    "# extract triples from the text\n",
    "\n",
    "\n",
    "def extract_relations_from_model_output(text, sentence):\n",
    "    relations = []\n",
    "    relation, subject, object_ = '', '', ''\n",
    "    current = 'x'\n",
    "    text_replaced = text.replace(\"<s>\", \"\").replace(\n",
    "        \"<pad>\", \"\").replace(\"</s>\", \"\")\n",
    "\n",
    "    for token in text_replaced.split():\n",
    "        if token == \"<triplet>\":\n",
    "            current = 't'\n",
    "            if relation and subject and object_:\n",
    "                relations.append({\n",
    "                    'head': subject.strip(),\n",
    "                    'type': relation.strip(),\n",
    "                    'tail': object_.strip(),\n",
    "                    # Initialize with empty spans list\n",
    "                    'meta': {'sentence': sentence, 'spans': []}\n",
    "                })\n",
    "                relation, subject, object_ = '', '', ''\n",
    "        elif token == \"<subj>\":\n",
    "            current = 's'\n",
    "        elif token == \"<obj>\":\n",
    "            current = 'o'\n",
    "        else:\n",
    "            if current == 't':\n",
    "                subject += ' ' + token\n",
    "            elif current == 's':\n",
    "                object_ += ' ' + token\n",
    "            elif current == 'o':\n",
    "                relation += ' ' + token\n",
    "\n",
    "    # Add last triple if exists\n",
    "    if subject and relation and object_:\n",
    "        relations.append({\n",
    "            'head': subject.strip(),\n",
    "            'type': relation.strip(),\n",
    "            'tail': object_.strip(),\n",
    "            # Initialize with empty spans list\n",
    "            'meta': {'sentence': sentence, 'spans': []}\n",
    "        })\n",
    "    return relations\n",
    "\n",
    "\n",
    "# construct KG\n",
    "def from_text_to_kb(text, kb, span_length=64):\n",
    "\n",
    "    sentences = [sentence.strip()\n",
    "                for sentence in text.split(\".\") if sentence.strip()]\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # Use spaCy to enhance relations with dependency parsing\n",
    "        spacy_relations = extract_spacy_relations(sentence)\n",
    "\n",
    "        # Combine Rebel and spaCy relations for a more comprehensive KB\n",
    "        for relation in spacy_relations:  # or extend with rebel_relations if using both\n",
    "            kb.add_relation(relation)\n",
    "\n",
    "        # Use Rebel model to extract relations\n",
    "        inputs = tokenizer([sentence], return_tensors=\"pt\")\n",
    "\n",
    "        # Compute span boundaries for the sentence\n",
    "        num_tokens = len(inputs[\"input_ids\"][0])\n",
    "        num_spans = math.ceil(num_tokens / span_length)\n",
    "        overlap = math.ceil(\n",
    "            (num_spans * span_length - num_tokens) / max(num_spans - 1, 1))\n",
    "        spans_boundaries = []\n",
    "        start = 0\n",
    "        for i in range(num_spans):\n",
    "            spans_boundaries.append(\n",
    "                [start + span_length * i, start + span_length * (i + 1)])\n",
    "            start -= overlap\n",
    "\n",
    "        tensor_ids = [inputs[\"input_ids\"][0][boundary[0]:boundary[1]]\n",
    "                    for boundary in spans_boundaries]\n",
    "        tensor_masks = [inputs[\"attention_mask\"][0][boundary[0]                                                    :boundary[1]] for boundary in spans_boundaries]\n",
    "        # inputs = {\"input_ids\": torch.stack(tensor_ids), \"attention_mask\": torch.stack(tensor_masks)}\n",
    "        inputs = {\"input_ids\": torch.stack(tensor_ids).to(\n",
    "            device), \"attention_mask\": torch.stack(tensor_masks).to(device)}\n",
    "\n",
    "        # Generate triples for the sentence\n",
    "        num_return_sequences = 5\n",
    "        gen_kwargs = {\n",
    "            \"max_length\": 512,\n",
    "            \"length_penalty\": 1.0,\n",
    "            \"num_beams\": 5,\n",
    "            \"num_return_sequences\": num_return_sequences\n",
    "        }\n",
    "\n",
    "        generated_tokens = model.generate(**inputs, **gen_kwargs)\n",
    "        decoded_preds = tokenizer.batch_decode(\n",
    "            generated_tokens, skip_special_tokens=False)\n",
    "\n",
    "        for sentence_pred in decoded_preds:\n",
    "            relations = extract_relations_from_model_output(\n",
    "                sentence_pred, sentence)\n",
    "            for relation in relations:\n",
    "                kb.add_relation(relation)\n",
    "\n",
    "    return kb\n",
    "\n",
    "# Example usage\n",
    "# text = \"\"\"\n",
    "# AI ethics addresses questions of fairness, transparency, and accountability in AI design. Machine learning involves training algorithms on data to make predictions or decisions. Natural Language Processing is a major field in AI that enables interaction between humans and computers using natural language\n",
    "# \"\"\"\n",
    "# # Generate KB from text\n",
    "# kb = KB()\n",
    "# kb = from_text_to_kb(text, kb)\n",
    "# kb.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
